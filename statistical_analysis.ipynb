{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Salescope - Comprehensive Statistical Analysis of Walmart Sales Data\n",
        "\n",
        "**Developed and Analysed by:** [Srikar MK](https://www.linkedin.com/in/srikarmk/) & [Alekhya Bulusu](https://www.linkedin.com/in/alekhyabulusu/)\n",
        "\n",
        "This notebook provides a detailed statistical analysis of the Walmart sales dataset, including descriptive statistics, hypothesis testing, correlation analysis, and advanced statistical modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency, pearsonr, spearmanr, ttest_ind, mannwhitneyu\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('Walmart_Sales_Data.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Preprocessing and Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.time\n",
        "df['hour'] = pd.to_datetime(df['Time'].astype(str), format='%H:%M:%S').dt.hour\n",
        "df['day_name'] = df['Date'].dt.day_name()\n",
        "df['month_name'] = df['Date'].dt.month_name()\n",
        "df['day_of_week'] = df['Date'].dt.dayofweek\n",
        "df['is_weekend'] = df['day_of_week'].isin([5, 6])\n",
        "\n",
        "def time_of_day(t):\n",
        "    if t >= pd.to_datetime('05:00:00').time() and t < pd.to_datetime('12:00:00').time():\n",
        "        return 'Morning'\n",
        "    elif t >= pd.to_datetime('12:00:00').time() and t < pd.to_datetime('17:00:00').time():\n",
        "        return 'Afternoon'\n",
        "    else:\n",
        "        return 'Evening'\n",
        "\n",
        "df['time_of_day'] = df['Time'].apply(time_of_day)\n",
        "\n",
        "numeric_columns = ['Unit price', 'Quantity', 'Tax 5%', 'Total', 'cogs', 'gross margin percentage', 'gross income', 'Rating']\n",
        "for col in numeric_columns:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "print(\"Data preprocessing completed!\")\n",
        "print(f\"Dataset shape after preprocessing: {df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Descriptive Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
        "print(\"\\n1. Dataset Overview:\")\n",
        "print(f\"Total records: {len(df):,}\")\n",
        "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
        "print(f\"Number of unique customers: {df['Invoice ID'].nunique():,}\")\n",
        "print(f\"Number of branches: {df['Branch'].nunique()}\")\n",
        "print(f\"Number of cities: {df['City'].nunique()}\")\n",
        "\n",
        "print(\"\\n2. Revenue Statistics:\")\n",
        "print(f\"Total revenue: ${df['Total'].sum():,.2f}\")\n",
        "print(f\"Average transaction value: ${df['Total'].mean():.2f}\")\n",
        "print(f\"Median transaction value: ${df['Total'].median():.2f}\")\n",
        "print(f\"Standard deviation: ${df['Total'].std():.2f}\")\n",
        "print(f\"Min transaction: ${df['Total'].min():.2f}\")\n",
        "print(f\"Max transaction: ${df['Total'].max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n3. Detailed Statistics for Numeric Variables:\")\n",
        "desc_stats = df[numeric_columns].describe()\n",
        "print(desc_stats.round(2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n4. Categorical Variables Distribution:\")\n",
        "categorical_vars = ['Branch', 'City', 'Customer type', 'Gender', 'Product line', 'Payment']\n",
        "\n",
        "for var in categorical_vars:\n",
        "    print(f\"\\n{var}:\")\n",
        "    value_counts = df[var].value_counts()\n",
        "    for value, count in value_counts.items():\n",
        "        percentage = (count / len(df)) * 100\n",
        "        print(f\"  {value}: {count:,} ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Distribution Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "key_variables = ['Total', 'Unit price', 'Quantity', 'Rating', 'Tax 5%', 'gross income']\n",
        "\n",
        "for i, var in enumerate(key_variables):\n",
        "    axes[i].hist(df[var].dropna(), bins=30, alpha=0.7, edgecolor='black')\n",
        "    axes[i].set_title(f'Distribution of {var}')\n",
        "    axes[i].set_xlabel(var)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "    \n",
        "    mean_val = df[var].mean()\n",
        "    median_val = df[var].median()\n",
        "    axes[i].axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
        "    axes[i].axvline(median_val, color='green', linestyle='--', label=f'Median: {median_val:.2f}')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== NORMALITY TESTS ===\")\n",
        "print(\"\\nShapiro-Wilk Test for Normality (sample size < 5000):\")\n",
        "print(\"H0: Data is normally distributed\")\n",
        "print(\"H1: Data is not normally distributed\")\n",
        "print(\"\\nResults:\")\n",
        "\n",
        "for var in key_variables:\n",
        "    sample_data = df[var].dropna().sample(min(5000, len(df[var].dropna())))\n",
        "    \n",
        "    if len(sample_data) > 3:  # Minimum sample size for Shapiro-Wilk\n",
        "        stat, p_value = stats.shapiro(sample_data)\n",
        "        print(f\"{var}: Statistic={stat:.4f}, p-value={p_value:.4f}\")\n",
        "        if p_value < 0.05:\n",
        "            print(f\"  → Reject H0: {var} is NOT normally distributed\")\n",
        "        else:\n",
        "            print(f\"  → Fail to reject H0: {var} appears normally distributed\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Correlation Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correlation_matrix = df[numeric_columns].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, fmt='.3f', cbar_kws={'shrink': 0.8})\n",
        "plt.title('Correlation Matrix of Numeric Variables')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Hypothesis Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== HYPOTHESIS TESTING ===\")\n",
        "print(\"\\n1. Gender Differences in Total Spending:\")\n",
        "print(\"H0: No difference in mean spending between genders\")\n",
        "print(\"H1: There is a difference in mean spending between genders\")\n",
        "\n",
        "male_spending = df[df['Gender'] == 'Male']['Total']\n",
        "female_spending = df[df['Gender'] == 'Female']['Total']\n",
        "\n",
        "print(f\"\\nMale spending: Mean = ${male_spending.mean():.2f}, Std = ${male_spending.std():.2f}\")\n",
        "print(f\"Female spending: Mean = ${female_spending.mean():.2f}, Std = ${female_spending.std():.2f}\")\n",
        "\n",
        "t_stat, p_value = ttest_ind(male_spending, female_spending)\n",
        "print(f\"\\nT-test results:\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"→ Reject H0: There IS a significant difference in spending between genders\")\n",
        "else:\n",
        "    print(\"→ Fail to reject H0: No significant difference in spending between genders\")\n",
        "\n",
        "pooled_std = np.sqrt(((len(male_spending) - 1) * male_spending.var() + \n",
        "                     (len(female_spending) - 1) * female_spending.var()) / \n",
        "                    (len(male_spending) + len(female_spending) - 2))\n",
        "cohens_d = (male_spending.mean() - female_spending.mean()) / pooled_std\n",
        "print(f\"\\nEffect size (Cohen's d): {cohens_d:.4f}\")\n",
        "if abs(cohens_d) < 0.2:\n",
        "    print(\"→ Small effect size\")\n",
        "elif abs(cohens_d) < 0.5:\n",
        "    print(\"→ Medium effect size\")\n",
        "else:\n",
        "    print(\"→ Large effect size\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\\n2. Chi-Square Tests for Categorical Associations:\")\n",
        "\n",
        "print(\"\\nGender vs Product Line:\")\n",
        "print(\"H0: Gender and Product line are independent\")\n",
        "print(\"H1: Gender and Product line are associated\")\n",
        "\n",
        "gender_product_crosstab = pd.crosstab(df['Gender'], df['Product line'])\n",
        "chi2, p_value, dof, expected = chi2_contingency(gender_product_crosstab)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"→ Reject H0: Gender and Product line ARE associated\")\n",
        "else:\n",
        "    print(\"→ Fail to reject H0: Gender and Product line are independent\")\n",
        "\n",
        "\n",
        "print(\"\\n\\nCustomer Type vs Payment Method:\")\n",
        "print(\"H0: Customer type and Payment method are independent\")\n",
        "print(\"H1: Customer type and Payment method are associated\")\n",
        "\n",
        "customer_payment_crosstab = pd.crosstab(df['Customer type'], df['Payment'])\n",
        "chi2, p_value, dof, expected = chi2_contingency(customer_payment_crosstab)\n",
        "\n",
        "print(f\"Chi-square statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "print(f\"Degrees of freedom: {dof}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"→ Reject H0: Customer type and Payment method ARE associated\")\n",
        "else:\n",
        "    print(\"→ Fail to reject H0: Customer type and Payment method are independent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Summary and Conclusions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== STATISTICAL ANALYSIS SUMMARY ===\")\n",
        "print(f\"\\nDataset Overview:\")\n",
        "print(f\"• Total transactions: {len(df):,}\")\n",
        "print(f\"• Total revenue: ${df['Total'].sum():,.2f}\")\n",
        "print(f\"• Average transaction value: ${df['Total'].mean():.2f}\")\n",
        "print(f\"• Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "print(f\"\\nKey Findings:\")\n",
        "print(f\"• Peak revenue day: {df.groupby('day_name')['Total'].sum().idxmax()}\")\n",
        "print(f\"• Peak revenue hour: {df.groupby('hour')['Total'].sum().idxmax()}:00\")\n",
        "print(f\"• Most popular product line: {df['Product line'].value_counts().index[0]}\")\n",
        "print(f\"• Most common payment method: {df['Payment'].value_counts().index[0]}\")\n",
        "print(f\"• Gender distribution: {df['Gender'].value_counts().to_dict()}\")\n",
        "print(f\"• Customer type distribution: {df['Customer type'].value_counts().to_dict()}\")\n",
        "\n",
        "print(f\"\\nBusiness Insights:\")\n",
        "print(f\"• The dataset shows significant patterns in customer behavior\")\n",
        "print(f\"• Time-based factors (hour, day) are important predictors of spending\")\n",
        "print(f\"• Product line and customer demographics influence transaction values\")\n",
        "print(f\"• Statistical tests reveal meaningful differences across customer segments\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
